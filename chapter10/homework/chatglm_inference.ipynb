{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc5bde60-1899-461d-8083-3ee04ac7c099",
   "metadata": {},
   "source": [
    "# 模型推理 - 使用 QLoRA 微调后的 ChatGLM-6B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3292b88c-91f0-48d2-91a5-06b0830c7e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModel, AutoTokenizer, BitsAndBytesConfig\n",
    "\n",
    "# 模型ID或本地路径\n",
    "model_name_or_path = 'THUDM/chatglm3-6b'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f81454c-24b2-4072-ab05-b25f9b120ae6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "324383a3db474f53acd88b1b684ba908",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_compute_dtype_map = {\n",
    "    'fp32': torch.float32,\n",
    "    'fp16': torch.float16,\n",
    "    'bf16': torch.bfloat16\n",
    "}\n",
    "\n",
    "# QLoRA 量化配置\n",
    "q_config = BitsAndBytesConfig(load_in_4bit=True,\n",
    "                              bnb_4bit_quant_type='nf4',\n",
    "                              bnb_4bit_use_double_quant=True,\n",
    "                              bnb_4bit_compute_dtype=_compute_dtype_map['bf16'])\n",
    "\n",
    "# 加载量化后模型(与微调的 revision 保持一致）\n",
    "base_model = AutoModel.from_pretrained(model_name_or_path,\n",
    "                                      quantization_config=q_config,\n",
    "                                      device_map='auto',\n",
    "                                      trust_remote_code=True,\n",
    "                                      revision='b098244')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d488846f-41bb-4fe6-9f09-0f392f3b39e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGLMForConditionalGeneration(\n",
       "  (transformer): ChatGLMModel(\n",
       "    (embedding): Embedding(\n",
       "      (word_embeddings): Embedding(65024, 4096)\n",
       "    )\n",
       "    (rotary_pos_emb): RotaryEmbedding()\n",
       "    (encoder): GLMTransformer(\n",
       "      (layers): ModuleList(\n",
       "        (0-27): 28 x GLMBlock(\n",
       "          (input_layernorm): RMSNorm()\n",
       "          (self_attention): SelfAttention(\n",
       "            (query_key_value): Linear4bit(in_features=4096, out_features=4608, bias=True)\n",
       "            (core_attention): CoreAttention(\n",
       "              (attention_dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (dense): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "          )\n",
       "          (post_attention_layernorm): RMSNorm()\n",
       "          (mlp): MLP(\n",
       "            (dense_h_to_4h): Linear4bit(in_features=4096, out_features=27392, bias=False)\n",
       "            (dense_4h_to_h): Linear4bit(in_features=13696, out_features=4096, bias=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (final_layernorm): RMSNorm()\n",
       "    )\n",
       "    (output_layer): Linear(in_features=4096, out_features=65024, bias=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model.requires_grad_(False)\n",
    "base_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e4270e2-c827-450e-bf27-7cb43a97f8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path,\n",
    "                                          trust_remote_code=True,\n",
    "                                          revision='b098244')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63408b60-876e-4eda-b501-90f842cca002",
   "metadata": {},
   "source": [
    "## 使用原始 ChatGLM3-6B 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ef405cf-7d77-41a6-a07b-c6c768ee30cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = \"解释下乾卦是什么？\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "566ed80e-828b-4105-b6e6-49de8905c991",
   "metadata": {},
   "outputs": [],
   "source": [
    "response, history = base_model.chat(tokenizer, query=input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6cee217e-f276-4c2f-94e7-69afb6d541a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "乾卦是《易经》中的第一卦，也是八卦之一。乾卦的卦象是由三个阳爻夹一个阴爻构成，象征着天、阳气、强盛、刚健等含义。乾卦的含义非常丰富，它不仅代表了宇宙的运行和自然界的规律，还象征着人类的道德品质和行为准则。\n",
      "\n",
      "在《易经》中，乾卦的卦辞是“元、亨、利、贞”，这四个字分别代表了乾卦的四种基本性质。其中，“元”表示宇宙的最高原理和道德准则；“亨”表示事物发展顺利、通行无阻；“利”表示和谐、美好、富有收益；“贞”表示正误、正邪、正邪之间的区别。\n",
      "\n",
      "乾卦的六爻分别代表了不同的时间段和不同的 moral 品质。最下层的爻代表阳爻，表示最纯的道德品质和行为准则；中间的爻代表阳爻和阴爻的组合，表示人类行为中的善恶交织，需要不断地调整和修正；“上”表示最高境界和道德品质。\n",
      "\n",
      "乾卦的运用可以帮助人们认识自然、掌握规律、提高道德品质，并在生活和工作中做出正确的决策。\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db3245d-037d-4fe5-ac0d-cc5e82742399",
   "metadata": {},
   "source": [
    "#### 询问一个64卦相关问题（应该不在 ChatGLM3-6B 预训练数据中）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bbe1395f-39c2-4759-ae81-90ef3bcfae47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "讼卦是《易经》中的第五卦，它是由两个阴爻夹一个阳爻构成，象征着诉讼、争端、矛盾等不和谐的因素。讼卦的含义非常丰富，它不仅代表了人类社会中的矛盾和纷争，还反映了人们处理这些问题的方法和态度。\n",
      "\n",
      "在《易经》中，讼卦的卦辞是“损、贞”，这四个字分别代表了讼卦的四种基本性质。其中，“损”表示减少、降低、损失，表示通过谦逊、退让等方式化解矛盾和纷争；“贞”表示正误、正邪、正邪之间的区别，表示在处理矛盾和纷争时要明确是非曲直。\n",
      "\n",
      "讼卦的六爻分别代表了不同的时间段和不同的处理方式。最下层的爻表示两个阴爻，表示矛盾和纷争的根源，需要通过沟通、协商等方式来解决；中间的爻表示两个阴爻和一个阳爻的组合，表示在解决矛盾和纷争时要保持公正、客观；“上”表示最高境界和处理方式，表示通过智慧和正义的方式来化解矛盾和纷争。\n",
      "\n",
      "讼卦的运用可以帮助人们认识和处理社会矛盾和纷争，提高处理问题的能力和智慧，避免矛盾的进一步升级。同时，讼卦也提醒人们要保持谦虚、退让的态度，以和平的方式解决矛盾和纷争。\n"
     ]
    }
   ],
   "source": [
    "response, history = base_model.chat(tokenizer, query=\"周易中的讼卦是什么？\", history=history)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342b3659-d644-4232-8af1-f092e733bf40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6d23e720-dee1-4b43-a298-0cbe1d8ad11d",
   "metadata": {},
   "source": [
    "## 使用微调后的 ChatGLM3-6B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bcfc5a2-41ed-405c-a31c-dca4fbb67425",
   "metadata": {},
   "source": [
    "### 加载 QLoRA Adapter(Epoch=3, automade-dataset(fixed)) - 请根据训练时间戳修改 timestamp "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c767c67-42aa-459c-a096-e226226c359b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import PeftModel, PeftConfig\n",
    "\n",
    "epochs = 3\n",
    "# timestamp = \"20240118_164514\"\n",
    "timestamp = \"20240426_173311\"\n",
    "\n",
    "peft_model_path = f\"models/{model_name_or_path}-epoch{epochs}-{timestamp}\"\n",
    "\n",
    "config = PeftConfig.from_pretrained(peft_model_path)\n",
    "qlora_model = PeftModel.from_pretrained(base_model, peft_model_path)\n",
    "training_tag=f\"ChatGLM3-6B(Epoch=3, automade-dataset(fixed))-{timestamp}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "24a5d22b-2c94-4dcf-8135-18d78f98755f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_chatglm_results(query, base_model, qlora_model, training_tag):\n",
    "    base_response, base_history = base_model.chat(tokenizer, query)\n",
    "\n",
    "    inputs = tokenizer(query, return_tensors=\"pt\").to(0)\n",
    "    ft_out = qlora_model.generate(**inputs, max_new_tokens=512)\n",
    "    ft_response = tokenizer.decode(ft_out[0], skip_special_tokens=True)\n",
    "    \n",
    "    print(f\"问题：{query}\\n\\n原始输出：\\n{base_response}\\n\\n\\n微调后（{training_tag}）：\\n{ft_response}\")\n",
    "    return base_response, ft_response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "062cd62e-69f9-4605-8c83-e468f71ef3d3",
   "metadata": {},
   "source": [
    "### 微调前后效果对比"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7db16cd5-0bb5-44ab-b861-d9ca6a4970c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "问题：解释下乾卦是什么？\n",
      "\n",
      "原始输出：\n",
      "{'name': '乾卦是八卦之一，由六个阳爻组成，象征着天。它所代表的是刚健、健行、刚健不屈的意境。乾卦的核心哲学是：天道刚健，运行不已，君子观此卦象，从而以天为法，自强不息。', 'content': '\\n乾卦象征天，为大通而至正。得此卦者，名利双收，应把握机会，争取成果。然而，切勿过于骄傲自满，而应保持谦逊、冷静和警惕。在事业、经商、求名等方面，乾卦皆暗示着大吉大利，但也警示着必须坚持正道、修养德行，方能永远亨通。\\n\\n在婚恋方面，乾卦提示着阳盛阴衰，但也强调刚柔相济，相互补足，形成美满的结果。在决策方面，则是强调刚健、正直、公允，自强不息的实质，需要修养德行、坚定信念，方能克服困难，消除灾难。'}\n",
      "\n",
      "\n",
      "微调后（ChatGLM3-6B(Epoch=3, automade-dataset(fixed))-20240426_173311）：\n",
      "[gMASK]sop 解释下乾卦是什么？ 在周易中，乾卦是六十四卦之首，由六个阳爻组成，象征着天。它所代表的是刚健、健行、刚健不屈的意境。乾卦的核心哲学是：天道刚健，运行不已，君子观此卦象，从而以天为法，自强不息。\n",
      "\n",
      "乾卦象征天，为大通而至正。得此卦者，名利双收，应把握机会，争取成果。然而，切勿过于骄傲自满，而应保持谦逊、冷静和警惕。在事业、经商、求名等方面，乾卦皆暗示着大吉大利，但也警示着必须坚持正道、修养德行，方能永远亨通。\n",
      "\n",
      "在婚恋方面，乾卦提示着阳盛阴衰，但也强调刚柔相济，相互补足，形成美满的结果。在决策方面，则是强调刚健、正直、公允，自强不息的实质，需要修养德行、坚定信念，方能克服困难，消除灾难。\n"
     ]
    }
   ],
   "source": [
    "base_response, ft_response = compare_chatglm_results(\"解释下乾卦是什么？\", base_model, qlora_model, training_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7aa074bd-c819-4533-a10f-f3184dc9549a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "问题：周易中的讼卦是什么\n",
      "\n",
      "原始输出：\n",
      "在周易中，讼卦是一个充满警示的卦象。它由上卦乾（天）和下卦坎（水）组成，代表着天与水背道而驰，形成争讼的局面。虽然事情开始时有利可图，但必须警惕戒惧，因为中间虽然吉利，但最终会带来凶险。对于涉及大川，涉水渡河的行动不利。因此，君子观此卦象，应当慎之又慎，杜绝争讼之事，并在谋事之初谨慎行事。讼卦的核心哲学是要避免争讼，退而让人，求得化解，安于正理，方可避免意外之灾。在事业上，务必避免介入诉讼纠纷的争执之中，与其这样，不如退而让人。即使最终获胜，也难免得失不均。经商方面，要坚持公正、公平、互利的原则，避免冲突，这样会有好结果。而对于求名、婚恋和决策，也都需要慎重行事，避免盲目追求，退让让人，可助事业、婚姻和决策的发展。\n",
      "\n",
      "\n",
      "微调后（ChatGLM3-6B(Epoch=3, automade-dataset(fixed))-20240426_173311）：\n",
      "[gMASK]sop 周易中的讼卦是什么? 在周易中，讼卦是一个充满警示的卦象。它由上卦乾（天）和下卦坎（水）组成，代表着天与水背道而驰，形成争讼的局面。虽然事情开始时有利可图，但必须警惕戒惧，因为中间虽然吉利，但最终会带来凶险。对于涉及大川，涉水渡河的行动不利。因此，君子观此卦象，应当慎之又慎，杜绝争讼之事，并在谋事之初谨慎行事。讼卦的核心哲学是要避免争讼，退而让人，求得化解，安于正理，方可避免意外之灾。在事业上，务必避免介入诉讼纠纷的争执之中，与其这样，不如退而让人。即使最终获胜，也难免得失不均。经商方面，要坚持公正、公平、互利的原则，避免冲突，这样会有好结果。而对于求名、婚恋和决策，也都需要慎重行事，避免盲目追求，退让让人，可助事业、婚姻和决策的发展。\n"
     ]
    }
   ],
   "source": [
    "base_response, ft_response = compare_chatglm_results(\"周易中的讼卦是什么\", base_model, qlora_model, training_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d5a31554-40f1-4e6e-8240-f207c4a61b42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "问题：师卦是什么？\n",
      "\n",
      "原始输出：\n",
      "在周易中，师卦是一个由坎卦（水）和坤卦（地）相叠而成的异卦。这一卦象代表着军队的力量和军情的总指挥，预示着吉祥无灾。象辞中描述了地中有水的情景，寓意着君子应当像大地一样容纳和畜养大众。师卦的解释强调选择德高望重的长者来统率军队，才能获得吉祥无咎。另外，师卦也象征着困难重重，需要包容别人、艰苦努力，及时行事，严于律已。在事业、经商、求名、婚恋等方面的决策中，都需要警惕潜在敌人，小心谨慎，合作与决断兼顾，方能成功。\n",
      "\n",
      "\n",
      "微调后（ChatGLM3-6B(Epoch=3, automade-dataset(fixed))-20240426_173311）：\n",
      "[gMASK]sop 师卦是什么？ 师卦是由坎卦（水）和坤卦（地）相叠而成。它象征着军队的力量和军情的总指挥，预示着吉祥无灾。在周易中，这是最吉利的卦象。\n",
      "\n",
      "师卦的核心观念是：顺其自然，随和相处，吉祥无灾。同时也强调了对自然规律的尊重和对未知领域的认知，强调顺应时代发展，遵循正道。\n",
      "\n",
      "在 business 领域，师卦象征着顺利组建团队，实现共同目标。同时也代表着潜在的困难，需要谨慎行事，及时解决。\n",
      "\n",
      "在事业和投资方面，师卦提示及时调整策略，防止风险，确保收益。需要明确目标，组织力量，实现共同目标，但也要警惕潜在的风险。\n",
      "\n",
      "师卦的核心哲学是：遵循自然，顺应时代，谨慎行事，及时解决问题，以确保顺利发展。\n"
     ]
    }
   ],
   "source": [
    "base_response, ft_response = compare_chatglm_results(\"师卦是什么？\", base_model, qlora_model, training_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abae8a8e-00bb-4801-931a-c942206f0e2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7d48183f-f1dc-4171-b217-e269a5b9c1b9",
   "metadata": {},
   "source": [
    "## 其他模型（错误数据或训练参数）\n",
    "\n",
    "#### 加载 QLoRA Adapter(Epoch=3, automade-dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "46a0e881-a4f3-43b2-8a61-0ec543a538a7",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Can't find 'adapter_config.json' at 'models/THUDM/chatglm3-6b-epoch3'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHFValidationError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/peft/lib/python3.11/site-packages/peft/config.py:108\u001b[0m, in \u001b[0;36mPeftConfigMixin.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, subfolder, **kwargs)\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 108\u001b[0m     config_file \u001b[38;5;241m=\u001b[39m \u001b[43mhf_hub_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    109\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCONFIG_NAME\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhf_hub_download_kwargs\u001b[49m\n\u001b[1;32m    110\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/peft/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py:111\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m arg_name \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrepo_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrom_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto_id\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m--> 111\u001b[0m     \u001b[43mvalidate_repo_id\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m arg_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m arg_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/peft/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py:159\u001b[0m, in \u001b[0;36mvalidate_repo_id\u001b[0;34m(repo_id)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m repo_id\u001b[38;5;241m.\u001b[39mcount(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 159\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HFValidationError(\n\u001b[1;32m    160\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRepo id must be in the form \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrepo_name\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnamespace/repo_name\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    161\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrepo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. Use `repo_type` argument if needed.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    162\u001b[0m     )\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m REPO_ID_REGEX\u001b[38;5;241m.\u001b[39mmatch(repo_id):\n",
      "\u001b[0;31mHFValidationError\u001b[0m: Repo id must be in the form 'repo_name' or 'namespace/repo_name': 'models/THUDM/chatglm3-6b-epoch3'. Use `repo_type` argument if needed.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m\n\u001b[1;32m      4\u001b[0m peft_model_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodels/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name_or_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-epoch\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 6\u001b[0m config \u001b[38;5;241m=\u001b[39m \u001b[43mPeftConfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpeft_model_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m qlora_model_e3 \u001b[38;5;241m=\u001b[39m PeftModel\u001b[38;5;241m.\u001b[39mfrom_pretrained(base_model, peft_model_path)\n\u001b[1;32m      8\u001b[0m training_tag \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChatGLM3-6B(Epoch=3, automade-dataset)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/peft/lib/python3.11/site-packages/peft/config.py:112\u001b[0m, in \u001b[0;36mPeftConfigMixin.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, subfolder, **kwargs)\u001b[0m\n\u001b[1;32m    108\u001b[0m         config_file \u001b[38;5;241m=\u001b[39m hf_hub_download(\n\u001b[1;32m    109\u001b[0m             pretrained_model_name_or_path, CONFIG_NAME, subfolder\u001b[38;5;241m=\u001b[39msubfolder, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mhf_hub_download_kwargs\n\u001b[1;32m    110\u001b[0m         )\n\u001b[1;32m    111\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m--> 112\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt find \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mCONFIG_NAME\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m at \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpretrained_model_name_or_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    114\u001b[0m loaded_attributes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mfrom_json_file(config_file)\n\u001b[1;32m    116\u001b[0m \u001b[38;5;66;03m# TODO: this hack is needed to fix the following issue (on commit 702f937):\u001b[39;00m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;66;03m# if someone saves a default config and loads it back with `PeftConfig` class it yields to\u001b[39;00m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;66;03m# not loading the correct config class.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;66;03m# print(peft_config)\u001b[39;00m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;66;03m# >>> PeftConfig(peft_type='ADALORA', auto_mapping=None, base_model_name_or_path=None, revision=None, task_type=None, inference_mode=False)\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: Can't find 'adapter_config.json' at 'models/THUDM/chatglm3-6b-epoch3'"
     ]
    }
   ],
   "source": [
    "from peft import PeftModel, PeftConfig\n",
    "\n",
    "epochs = 3\n",
    "peft_model_path = f\"models/{model_name_or_path}-epoch{epochs}\"\n",
    "\n",
    "config = PeftConfig.from_pretrained(peft_model_path)\n",
    "qlora_model_e3 = PeftModel.from_pretrained(base_model, peft_model_path)\n",
    "training_tag = f\"ChatGLM3-6B(Epoch=3, automade-dataset)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1f53196e-f523-4105-b04a-9ddab349cce1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'qlora_model_e3' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m base_response, ft_response \u001b[38;5;241m=\u001b[39m compare_chatglm_results(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m解释下乾卦是什么？\u001b[39m\u001b[38;5;124m\"\u001b[39m, base_model, \u001b[43mqlora_model_e3\u001b[49m, training_tag)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'qlora_model_e3' is not defined"
     ]
    }
   ],
   "source": [
    "base_response, ft_response = compare_chatglm_results(\"解释下乾卦是什么？\", base_model, qlora_model_e3, training_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "046306ad-6afe-4ec9-ae55-3df04f61d8f5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'qlora_model_e3' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m base_response, ft_response \u001b[38;5;241m=\u001b[39m compare_chatglm_results(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m地水师卦是什么？\u001b[39m\u001b[38;5;124m\"\u001b[39m, base_model, \u001b[43mqlora_model_e3\u001b[49m, training_tag)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'qlora_model_e3' is not defined"
     ]
    }
   ],
   "source": [
    "base_response, ft_response = compare_chatglm_results(\"地水师卦是什么？\", base_model, qlora_model_e3, training_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2ab3c310-8cc8-428a-91fa-964b7a58df43",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'qlora_model_e3' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m base_response, ft_response \u001b[38;5;241m=\u001b[39m compare_chatglm_results(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m周易中的讼卦是什么\u001b[39m\u001b[38;5;124m\"\u001b[39m, base_model, \u001b[43mqlora_model_e3\u001b[49m, training_tag)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'qlora_model_e3' is not defined"
     ]
    }
   ],
   "source": [
    "base_response, ft_response = compare_chatglm_results(\"周易中的讼卦是什么\", base_model, qlora_model_e3, training_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cfffcc5-afa6-45c1-985a-a3eb86a0d1c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8169237c-55d3-4d91-9f6b-8dbe635f1844",
   "metadata": {},
   "source": [
    "#### 加载 QLoRA Adapter(Epoch=50, Overfit, handmade-dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "72e6cc4f-c030-4107-b07a-6ef44f66a4b0",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Can't find 'adapter_config.json' at 'models/THUDM/chatglm3-6b-epoch50'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHFValidationError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/peft/lib/python3.11/site-packages/peft/config.py:108\u001b[0m, in \u001b[0;36mPeftConfigMixin.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, subfolder, **kwargs)\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 108\u001b[0m     config_file \u001b[38;5;241m=\u001b[39m \u001b[43mhf_hub_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    109\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCONFIG_NAME\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhf_hub_download_kwargs\u001b[49m\n\u001b[1;32m    110\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/peft/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py:111\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m arg_name \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrepo_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrom_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto_id\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m--> 111\u001b[0m     \u001b[43mvalidate_repo_id\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m arg_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m arg_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/peft/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py:159\u001b[0m, in \u001b[0;36mvalidate_repo_id\u001b[0;34m(repo_id)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m repo_id\u001b[38;5;241m.\u001b[39mcount(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 159\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HFValidationError(\n\u001b[1;32m    160\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRepo id must be in the form \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrepo_name\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnamespace/repo_name\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    161\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrepo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. Use `repo_type` argument if needed.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    162\u001b[0m     )\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m REPO_ID_REGEX\u001b[38;5;241m.\u001b[39mmatch(repo_id):\n",
      "\u001b[0;31mHFValidationError\u001b[0m: Repo id must be in the form 'repo_name' or 'namespace/repo_name': 'models/THUDM/chatglm3-6b-epoch50'. Use `repo_type` argument if needed.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m50\u001b[39m\n\u001b[1;32m      4\u001b[0m peft_model_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodels/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name_or_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-epoch\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 6\u001b[0m config \u001b[38;5;241m=\u001b[39m \u001b[43mPeftConfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpeft_model_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m qlora_model_e50_handmade \u001b[38;5;241m=\u001b[39m PeftModel\u001b[38;5;241m.\u001b[39mfrom_pretrained(base_model, peft_model_path)\n\u001b[1;32m      8\u001b[0m training_tag \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChatGLM3-6B(Epoch=50, handmade-dataset)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/peft/lib/python3.11/site-packages/peft/config.py:112\u001b[0m, in \u001b[0;36mPeftConfigMixin.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, subfolder, **kwargs)\u001b[0m\n\u001b[1;32m    108\u001b[0m         config_file \u001b[38;5;241m=\u001b[39m hf_hub_download(\n\u001b[1;32m    109\u001b[0m             pretrained_model_name_or_path, CONFIG_NAME, subfolder\u001b[38;5;241m=\u001b[39msubfolder, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mhf_hub_download_kwargs\n\u001b[1;32m    110\u001b[0m         )\n\u001b[1;32m    111\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m--> 112\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt find \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mCONFIG_NAME\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m at \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpretrained_model_name_or_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    114\u001b[0m loaded_attributes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mfrom_json_file(config_file)\n\u001b[1;32m    116\u001b[0m \u001b[38;5;66;03m# TODO: this hack is needed to fix the following issue (on commit 702f937):\u001b[39;00m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;66;03m# if someone saves a default config and loads it back with `PeftConfig` class it yields to\u001b[39;00m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;66;03m# not loading the correct config class.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;66;03m# print(peft_config)\u001b[39;00m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;66;03m# >>> PeftConfig(peft_type='ADALORA', auto_mapping=None, base_model_name_or_path=None, revision=None, task_type=None, inference_mode=False)\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: Can't find 'adapter_config.json' at 'models/THUDM/chatglm3-6b-epoch50'"
     ]
    }
   ],
   "source": [
    "from peft import PeftModel, PeftConfig\n",
    "\n",
    "epochs = 50\n",
    "peft_model_path = f\"models/{model_name_or_path}-epoch{epochs}\"\n",
    "\n",
    "config = PeftConfig.from_pretrained(peft_model_path)\n",
    "qlora_model_e50_handmade = PeftModel.from_pretrained(base_model, peft_model_path)\n",
    "training_tag = f\"ChatGLM3-6B(Epoch=50, handmade-dataset)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8d63b187-37be-4721-8959-098d0437c41d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'qlora_model_e50_handmade' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m base_response, ft_response \u001b[38;5;241m=\u001b[39m compare_chatglm_results(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m解释下乾卦是什么？\u001b[39m\u001b[38;5;124m\"\u001b[39m, base_model, \u001b[43mqlora_model_e50_handmade\u001b[49m, training_tag)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'qlora_model_e50_handmade' is not defined"
     ]
    }
   ],
   "source": [
    "base_response, ft_response = compare_chatglm_results(\"解释下乾卦是什么？\", base_model, qlora_model_e50_handmade, training_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "be5da80e-d1de-467f-a3bb-508d5a77a46d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'qlora_model_e50_handmade' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m base_response, ft_response \u001b[38;5;241m=\u001b[39m compare_chatglm_results(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m地水师卦\u001b[39m\u001b[38;5;124m\"\u001b[39m, base_model, \u001b[43mqlora_model_e50_handmade\u001b[49m, training_tag)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'qlora_model_e50_handmade' is not defined"
     ]
    }
   ],
   "source": [
    "base_response, ft_response = compare_chatglm_results(\"地水师卦\", base_model, qlora_model_e50_handmade, training_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "04f0eb9a-5075-4588-914a-2538bea801aa",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'qlora_model_e50_handmade' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m base_response, ft_response \u001b[38;5;241m=\u001b[39m compare_chatglm_results(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m天水讼卦\u001b[39m\u001b[38;5;124m\"\u001b[39m, base_model, \u001b[43mqlora_model_e50_handmade\u001b[49m, training_tag)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'qlora_model_e50_handmade' is not defined"
     ]
    }
   ],
   "source": [
    "base_response, ft_response = compare_chatglm_results(\"天水讼卦\", base_model, qlora_model_e50_handmade, training_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74814071-f1a6-4cea-bed4-91ebbcfb9331",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
